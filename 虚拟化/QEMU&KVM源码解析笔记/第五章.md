## 内存虚拟化

MMU虚拟化：当虚拟机中的虚拟CPU进行内存寻址的时候，要想访问到实际的物理地址，需要经历以下步骤，虚拟机内部的虚拟地址-->虚拟机内部的物理地址-->QEMU线程的虚拟地址-->物理机上的物理地址。

EPT方案：MMU虚拟化的具体实现方案，其CPU寻址方式在VM non-root operation下会发生变化，使用两个页表，分别是虚拟机页表（从虚拟机虚拟地址转换到虚拟机物理地址）和EPT页表（从虚拟机物理地址转换到宿主机物理地址）。

​	注：开启EPT，当CPU进行VM Entry时，会使用EPT功能；当CPU产生VM Exit时，EPT会关闭，此		   时CPU在宿主机上会按传统的单页表寻址方式

EPT寻址方式：

EPT共48位物理地址，四级页表每页表使用9位物理地址（页表内部的offset）和一个页内的偏移（12位）

![image-20201026204314480](https://gitee.com/zhzzhz/blog_warehouse/raw/master/img/image-20201026204314480.png)

#### QEMU内存初始化的基本结构

`AddressSpace`结构体：表示一个虚拟机或者虚拟CPU能够访问的所有物理地址（这里指的是寻址地址）

```c
 struct AddressSpace {
     /* private: */
     struct rcu_head rcu;
     char *name;
     MemoryRegion *root;  // 表示对应的一个根MemoryRegion
 
     /* Accessed via RCU.  */
     struct FlatView *current_map; // 该地址空间是平坦模式下的一个视图
 
     int ioeventfd_nb;
     struct MemoryRegionIoeventfd *ioeventfds;
     QTAILQ_HEAD(, MemoryListener) listeners;
     QTAILQ_ENTRY(AddressSpace) address_spaces_link;
 };
```

> IA-32处理器平台允许3种不同的访问系统内存的方法：
>
> （1）平坦内存模式
>
> （2）分段内存模式
>
> （3）实地址模式
>
> 平坦内存模式把全部系统内存表示为连续的地址空间。所有指令、数据和堆栈都包含在相同的地址空间中。通过称为线性地址（linear address）的特定地址访问每个内存位置。
>
> 分段内存模式把系统内存划分为独立段的组，通过位于段寄存器中的指针进行引用。每个段用于包含特定类型的数据。一个段用于包含指令码，另一个段用于包含数据元素，第三个段用于包含程序堆栈。
>
> 段中的内存位置是通过逻辑地址定义的。逻辑地址由段地址（存放在段寄存器中）和偏移地址构成。处理器把逻辑地址转换为相应的线性地址位置以便访问内存的字节。
>
> 如果程序使用实地址模式，那么所有段寄存器都指向零线性地址，并且不会被程序改动。所有指令码、数据元素、堆栈元素都是通过它们的线性地址直接访问的。

`MemoryRegion`结构体：表示虚拟机的一段内存区域

```c
struct MemoryRegion {
     Object parent_obj;
 
     /* private: */
 
     /* The following fields should fit in a cache line */
     bool romd_mode;
     bool ram;
     bool subpage;
     bool readonly; /* For RAM regions */
     bool nonvolatile;
     bool rom_device;
     bool flush_coalesced_mmio;
     bool global_locking;
     uint8_t dirty_log_mask;
     bool is_iommu;
     RAMBlock *ram_block;  // 实际分配的物理内存
     Object *owner;
 
     const MemoryRegionOps *ops; // 回调函数，例如MMIO的read，write
     void *opaque;
     MemoryRegion *container; // 表示该MemoryRegion所处的上一级MemoryRegion
     Int128 size;
     hwaddr addr; // MemoryRegion所在的虚拟机的物理地址
     void (*destructor)(MemoryRegion *mr);
     uint64_t align;
     bool terminates; // 是否是叶子节点
     bool ram_device;
     bool enabled;
     bool warning_printed; /* For reservations */
     uint8_t vga_logging_count;
     MemoryRegion *alias;
     hwaddr alias_offset;
     int32_t priority; // MemoryRegion的优先级
     QTAILQ_HEAD(, MemoryRegion) subregions;
     QTAILQ_ENTRY(MemoryRegion) subregions_link;
     QTAILQ_HEAD(, CoalescedMemoryRange) coalesced;
     const char *name;
     unsigned ioeventfd_nb;
     MemoryRegionIoeventfd *ioeventfds;
 };
```

常见的MemoryRegion有如下几类：

1. RAM：host上一段实际分配给虚拟机作为物理内存的虚拟内存
2. MMIO：guest的一段内存，但在宿主机上没有对应的虚拟内存，而是截获对这个区域的访问，调用对应读写函数用在设备模拟中
3. ROM：与RAM类似，但这类型内存是只读
4. ROM device：在读方面类似RAM，能直接读取，写方面类似MMIO，写入会调用对应的回调函数
5. container：包含若干个MemoryRegion，每一个Region在这个container的偏移都不一样。container主要将多个MemoryRegion合并成一个，例如PCI的MemoryRegion包括RAM和MMIO。
6. alias：region的另一个部分，可以使一个region被分成几个不连续的部分。

#### QEMU虚拟机内存初始化

内存分为低端内存和高端内存：

+ 如果用户在命令行指定了max-ram-below-4g参数，则使用用户指定的参数，这可以让一些非传统的虚拟机使用更多的4GB以下的地址空间

+ 如果用户没有指定max-ram-below-4g参数，则分两种情况：
  1. 传统的虚拟机（qemu-2.5以下）使用3.5GB（0xe0000000）作为分界线
  2. 高版本虚拟机会设置gigabyte_align，当虚拟机的内存大于传统低端内存（3.5GB）时，会以3GB作为分界线。超过lowmem的地址就是高端内存了。

`cpu_exec_init_all`进行初始化操作，其中的`io_mem_init`创建若干个包含所有地址空间的MemoryRegion，`memory_map_init`创建`address_space_memory`(虚拟机的内存地址空间)和`address_space_io`(I/O地址空间)

`pc_initl`函数与虚拟机内存虚拟化有关的部分：创建一个PCI地址空间pci_memory

+ 调用pc_memory_init函数进行内存初始化

  ```c
  FWCfgState *pc_memory_init(MachineState *machine,
                             MemoryRegion *system_memory,
                             ram_addr_t below_4g_mem_size,
                             ram_addr_t above_4g_mem_size,
                             MemoryRegion *rom_memory,
                             MemoryRegion **ram_memory,
                             PcGuestInfo *guest_info)
  {
      ......
      ram = g_malloc(sizeof(*ram));
      // 分配虚拟机的实际物理内存，name = "pc.ram"
      memory_region_allocate_system_memory(ram, NULL, "pc.ram",
                                           machine->ram_size);
      *ram_memory = ram;
      ram_below_4g = g_malloc(sizeof(*ram_below_4g));
      // 创建一个ram_below_4g region
      memory_region_init_alias(ram_below_4g, NULL, "ram-below-4g", ram,
                               0, below_4g_mem_size);
      // 将ram_below_4g设置为pc.ram子ragion
      memory_region_add_subregion(system_memory, 0, ram_below_4g);
      // 将小于4GB的内存加入到/etc/e820表中供BIOS使用
      e820_add_entry(0, below_4g_mem_size, E820_RAM);
      if (above_4g_mem_size > 0) {
          ram_above_4g = g_malloc(sizeof(*ram_above_4g));
          memory_region_init_alias(ram_above_4g, NULL, "ram-above-4g", ram,
                                   below_4g_mem_size, above_4g_mem_size);
          memory_region_add_subregion(system_memory, 0x100000000ULL,
                                      ram_above_4g);
          e820_add_entry(0x100000000ULL, above_4g_mem_size, E820_RAM);
      }
  
      ......
  
      /* Initialize PC system firmware */
      pc_system_firmware_init(rom_memory, guest_info->isapc_ram_fw);
  
      option_rom_mr = g_malloc(sizeof(*option_rom_mr));
      memory_region_init_ram(option_rom_mr, NULL, "pc.rom", PC_ROM_SIZE,
                             &error_abort);
      vmstate_register_ram_global(option_rom_mr);
      memory_region_add_subregion_overlap(rom_memory,
                                          PC_ROM_MIN_VGA,
                                          option_rom_mr,
                                          1);
  	// 创建fw_cfg设备
      fw_cfg = bochs_bios_init();
      // 将fw_cfg设备复制到全局变量fw_cfg中
      rom_set_fw(fw_cfg);
  
      if (guest_info->has_reserved_memory && pcms->hotplug_memory_base) {
          uint64_t *val = g_malloc(sizeof(*val));
          *val = cpu_to_le64(ROUND_UP(pcms->hotplug_memory_base, 0x1ULL << 30));
          fw_cfg_add_file(fw_cfg, "etc/reserved-memory-end", val, sizeof(*val));
      }
  
      if (linux_boot) {
          load_linux(fw_cfg, machine->kernel_filename, machine->initrd_filename,
                     machine->kernel_cmdline, below_4g_mem_size);
      }
  
      for (i = 0; i < nb_option_roms; i++) {
          rom_add_option(option_rom[i].name, option_rom[i].bootindex);
      }
      guest_info->fw_cfg = fw_cfg;
      return fw_cfg;
  }
  ```

#### 分配虚拟机RAM过程

RAM通过`memory_region_allocate_system_memory`函数分配，`allocate_system_memory_nonnuma`->`memory_region_init_ram`->`qemu_ram_alloc`

```c
void memory_region_allocate_system_memory(MemoryRegion *mr, Object *owner,
                                          const char *name,
                                          uint64_t ram_size)
{
    uint64_t addr = 0;
    int i;

    if (nb_numa_nodes == 0 || !have_memdevs) {
        allocate_system_memory_nonnuma(mr, owner, name, ram_size);
        return;
    }
	......
}

static void allocate_system_memory_nonnuma(MemoryRegion *mr, Object *owner,
                                           const char *name,
                                           uint64_t ram_size)
{
    if (mem_path) {
		......
    } else {
        memory_region_init_ram(mr, owner, name, ram_size, &error_abort);
    }
    vmstate_register_ram_global(mr);
}

void memory_region_init_ram(MemoryRegion *mr,
                            Object *owner,
                            const char *name,
                            uint64_t size,
                            Error **errp)
{
    memory_region_init(mr, owner, name, size);
    mr->ram = true;
    mr->terminates = true;
    mr->destructor = memory_region_destructor_ram;
    mr->ram_addr = qemu_ram_alloc(size, mr, errp); // 分配一个RAMBlock结构以及虚拟机物理内存对应的QEMU进程中的虚拟内存
}
```

RAMBlock结构体表示的是虚拟机中的一块内存条，里面记录了内存条的一些基本信息

`ram_block_add`函数将一块新的内存条加入到系统中

```c
static ram_addr_t ram_block_add(RAMBlock *new_block, Error **errp)
{
    RAMBlock *block;
    RAMBlock *last_block = NULL;
    // old_ram_size表示未添加新的new_block前的RAM大小，new_ram_size表示添加了new_block之后的RAM大小，两个单位都是页
    ram_addr_t old_ram_size, new_ram_size;
	// 获取整个RAM内存区间的大小
    old_ram_size = last_ram_offset() >> TARGET_PAGE_BITS;

    qemu_mutex_lock_ramlist();
    // find_ram_offset遍历ram_list，找到两个RAMBlock之间能容纳当前新加入的RAMBlock长度的最小空间
    new_block->offset = find_ram_offset(new_block->max_length);

    if (!new_block->host) {
        if (xen_enabled()) {
            xen_ram_alloc(new_block->offset, new_block->max_length,
                          new_block->mr);
        } else {
            // 调用mmap来分配内存，host表示的是虚拟机物理地址对应的QEMU进程地址空间的虚拟内存
            new_block->host = phys_mem_alloc(new_block->max_length,
                                             &new_block->mr->align);
            if (!new_block->host) {
                error_setg_errno(errp, errno,
                                 "cannot set up guest memory '%s'",
                                 memory_region_name(new_block->mr));
                qemu_mutex_unlock_ramlist();
                return -1;
            }
            memory_try_enable_merging(new_block->host, new_block->max_length);
        }
    }
    
	// 找到小于要添加的block大小的block，将刚创建的内存空间插入相应位置
    
	/* Keep the list sorted from biggest to smallest block.  Unlike QTAILQ,
     * QLIST (which has an RCU-friendly variant) does not have insertion at
     * tail, so save the last element in last_block.
     */
    QLIST_FOREACH_RCU(block, &ram_list.blocks, next) {
        last_block = block;
        if (block->max_length < new_block->max_length) {
            break;
        }
    }
    if (block) {
        QLIST_INSERT_BEFORE_RCU(block, new_block, next);
    } else if (last_block) {
        QLIST_INSERT_AFTER_RCU(last_block, new_block, next);
    } else { /* list is empty */
        QLIST_INSERT_HEAD_RCU(&ram_list.blocks, new_block, next);
    }
    ram_list.mru_block = NULL;

    /* Write list before version */
    smp_wmb();
    ram_list.version++;
    qemu_mutex_unlock_ramlist();
    // 计算现在的RAM内存大小
    new_ram_size = last_ram_offset() >> TARGET_PAGE_BITS;

    if (new_ram_size > old_ram_size) {
        int i;

        /* ram_list.dirty_memory[] is protected by the iothread lock.  */
        for (i = 0; i < DIRTY_MEMORY_NUM; i++) {
            ram_list.dirty_memory[i] =
                bitmap_zero_extend(ram_list.dirty_memory[i],
                                   old_ram_size, new_ram_size);
       }
    }
    cpu_physical_memory_set_dirty_range(new_block->offset,
                                        new_block->used_length);

    if (new_block->host) {
        qemu_ram_setup_dump(new_block->host, new_block->max_length);
        qemu_madvise(new_block->host, new_block->max_length, QEMU_MADV_HUGEPAGE);
        qemu_madvise(new_block->host, new_block->max_length, QEMU_MADV_DONTFORK);
        if (kvm_enabled()) {
            kvm_setup_guest_memory(new_block->host, new_block->max_length);
        }
    }

    return new_block->offset;
}
```

### 内存布局的提交

#### 内存更改通知

`MemoryListener`的作用：为了让EPT正常工作，将虚拟机的内存布局通知到KVM，并且每次变化都需要通知KVM进行修改。

所有对内存更改感兴趣的模块都可以注册自己的`MemoryListener`，不同`MemoryListener`之间用该结构体里的link来连接，其头节点是一个全局变量`memory_lisyeners`。同一地址空间的`MemoryListener`还会用结构体内的`link_as`进行连接。

`commit`过程：当修改了虚拟机的内存布局或者属性时，就需要通知到各个listener。

其一共有三个步骤：

1. 调用memory listener的begin函数，进行一些初始化工作
2. 更新AddressSpace的内存视图
3. 对全局链表memory_listeners上的每一个注册的MemoryListener调用commit回调函数

#### 虚拟机内存平坦化过程

虚拟机内存的平坦化过程指的是将AddressSpace根MemoryRegion表示的虚拟机内存地址空间转变成一个平坦的线性地址空间。

虚拟机内存的平坦化是以AddressSpace的根MemoryRegion为起点，**将其表示的内存拓扑的无环图结构变成平坦模式**。（变成FlatRange数组里面的一个个下标）

虚拟机平坦内存的数据结构是FlagView

```c
struct FlatView {
    struct rcu_head rcu;
    unsigned ref;
    FlatRange *ranges;
    unsigned nr;	// 表示FlagRange的个数
    unsigned nr_allocated;	// 表示已分配的FlatRange个数
};
struct FlatRange {
    MemoryRegion *mr;	// 表示对应的MemoryRegion
    hwaddr offset_in_region;	// 该FlatRange在MemoryRegion的偏移
    AddrRange addr;	// 表示地址和大小（感觉是物理地址，但是又不对的亚子）
    uint8_t dirty_log_mask;
    bool romd_mode;
    bool readonly;
};
```

`generate_memory_topology`函数负责生成FlatView，该函数总共两个功能：

1. 将MemoryRegion展开（这里指的是复合的MemoryRegion），并且把数据记录到一个FlatView中
2. 将FlatView中能合并的FlatRange进行合并

`generate_memory_topology`中的`render_memory_region`是内存平坦化的核心函数：本质是实现`generate_memory_topology`函数的第一个功能，也就是将一个MemoryRegion转化成若干个FlatRange，然后插入到第一个参数FlatView的FlatRange成员中。

![image-20201027212641071](https://gitee.com/zhzzhz/blog_warehouse/raw/master/img/image-20201027212641071.png)

具体操作如下：

1. 计算出一个clip（mr所表示的范围，可以理解为大小）

2. 识别出MemoryRegion是一个复合的，那么拆分，准备平坦化子region（这里是mr1），这里又经历了一次计算clip

3. 计算一个offset_in_region，也就是马上创建的FlatRange相对于mr1的起始位置（这里就是mr1的起始位置）

4. 初始化FlatRange

   ![image-20201027213632716](https://gitee.com/zhzzhz/blog_warehouse/raw/master/img/image-20201027213632716.png)

5. 准备展开mr1，但是此时mr1可能有一部分已经被展开，所以需要遍历view中的所有FlatRange，如果base大于FlatRange的最后长度，则不用理会，反之，base小于的话就准备将其展开

6. 计算左边深色区域的长度，起始位置，然后将其变成FlatRange插入view中，将base更新到range2，remain更新为右边深色长度+range2长度

7. 越过range2，也就是加上range2的长度

8. 和6相同

最终结果就是view中填满了以mr为根的FlatRange，如果FlatRange是紧邻的，并且各种属性相同，就可以合并。

#### 向KVM注册内存

AddressSpace上的内存布局主要由`address_space_update_topology`函数来更新，并且把内存拓扑信息同步到KVM。

下面是更新的具体步骤：

1. 根据FlantRange创建一个MemoryRegionSection

2. 依据size，start_addr，ram等构造一个类型为KVMSlot的mem变量

   ```c
   /* 
   定义的地址在/include/exec/memory.h
   MemoryRegionSection：描述MemoryRegion的片段
   */
   struct MemoryRegionSection {
       Int128 size;
       MemoryRegion *mr;
       FlatView *fv;
       hwaddr offset_within_region;	// 可能是一个复合Region里面属于这个子Region的起始位置为mr的offset？
       hwaddr offset_within_address_space;	// 虚拟机的物理地址
       bool readonly;
       bool nonvolatile;
   };
   
   static void kvm_set_phys_mem(MemoryRegionSection *section, bool add)
   {
       KVMState *s = kvm_state;
       KVMSlot *mem, old;
       int err;
       MemoryRegion *mr = section->mr;
       bool log_dirty = memory_region_is_logging(mr);
       bool writeable = !mr->readonly && !mr->rom_device;
       bool readonly_flag = mr->readonly || memory_region_is_romd(mr);
       // 表示该MemoryRegionSection在AddressSpace中的起始地址
       hwaddr start_addr = section->offset_within_address_space;
       ram_addr_t size = int128_get64(section->size);
       void *ram = NULL;
   	......
       // 表示该MemoryRegionSection在虚拟机内存中对应的QEMU虚拟地址空间的虚拟地址
       ram = memory_region_get_ram_ptr(mr) + section->offset_within_region + delta;
   
       ......
       mem = kvm_alloc_slot(s);
       mem->memory_size = size;
       mem->start_addr = start_addr;
       mem->ram = ram;
       mem->flags = kvm_mem_flags(s, log_dirty, readonly_flag);
   
       err = kvm_set_user_memory_region(s, mem);
       if (err) {
           fprintf(stderr, "%s: error registering slot: %s\n", __func__,
                   strerror(-err));
           abort();
       }
   }
   ```

3. 将QEMU表示内存槽的KVMSlot转换成KVM表示内存槽的kvm_userspace_memory_region结构

   ```c
   static int kvm_set_user_memory_region(KVMState *s, KVMSlot *slot)
   {
       struct kvm_userspace_memory_region mem;
   
       mem.slot = slot->slot;
       // 表示虚拟机的物理地址
       mem.guest_phys_addr = slot->start_addr;
       // 虚拟对应的QEMU进程的虚拟地址
       mem.userspace_addr = (unsigned long)slot->ram;
       mem.flags = slot->flags;
       if (s->migration_log) {
           mem.flags |= KVM_MEM_LOG_DIRTY_PAGES;
       }
   
       if (slot->memory_size && mem.flags & KVM_MEM_READONLY) {
           /* Set the slot size to 0 before setting the slot to the desired
            * value. This is needed based on KVM commit 75d61fbc. */
           mem.memory_size = 0;
           kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
       }
       mem.memory_size = slot->memory_size;
       return kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
   }
   ```

4. 设置完毕后调用ioctl(KVM_SET_USER_MEMORY_REGION)来设置虚拟机的物理地址和QEMU虚拟地址的映射关系，这样虚拟机对物理地址的访问其实就是对QEMU这里虚拟地址的访问

### 内存的分派

#### 内存分派表的构建

QEMU的内存分派指的是，当给定一个AddressSpace和一个地址时，能够快速地找到其所在的MemoryRegionSection，从而找到对应的MemoryRegion

在上面展示的AddressSpace结构体中的dispatch成员AddressSpaceDispatch记录了该AddressSpace中的分派信息

```c
struct AddressSpaceDispatch {
    struct rcu_head rcu;

    MemoryRegionSection *mru_section; // 作为一个缓存，保存最近一次找到的MemoryRegionSection
    
    /* This is a multi-level map on the physical address space.
     * The bottom level has pointers to MemoryRegionSections.
     */
    PhysPageEntry phys_map; // 类似于寻址的CR3，指向第一级页表
    PhysPageMap map;
    AddressSpace *as;
};


struct PhysPageEntry {
    // 这里的:是位域，相当于把uint32_t的32位byte分割成6和26，分别给skip和ptr
    /* How many bits skip to next level (in units of L2_SIZE). 0 for a leaf. */
    uint32_t skip : 6;
     /* index into phys_sections (!skip) or phys_map_nodes (skip) */
    uint32_t ptr : 26; // 在非叶子节点会索引nodes中的项
};

typedef struct PhysPageMap {
    struct rcu_head rcu;
	// sections指向所有的MemoryRegionSection
    unsigned sections_nb;
    unsigned sections_nb_alloc;
    unsigned nodes_nb;
    unsigned nodes_nb_alloc;
    Node *nodes; // 表示中间节点（类似于页表项）
    MemoryRegionSection *sections; // 指向所有的MemoryRegionSection
} PhysPageMap;
```

寻址：

这里的寻址方式类似于MMU的寻址过程，在AddressSpaceDispatch中的phys_map找到第一级页表（PhysPageEntry中ptr指向的nodes中的一个Node），然后将要访问的物理地址按位进行分解，作为找到的Node的索引，最后一个PhyPageEntry中的ptr存放着一个用来索引sections数组的值，这样最终得到MemoryRegionSection。

页表创建：

页表创建就是在上述的基础上加入页异常机制，判断当前的页目录项对应的页表是否存在，不存在就调用phys_map_node_alloc分配一个页表



当然，如果你的MemoryRegioinSection不到一页的话，那么就需要用到`register_subpage`函数，这种情况一般常用于I/O地址空间，通常设备都只有几个I/O端口。

基本流程如下：

1. 根据phys_map指向的第一级页表的基址构造出一个MemoryRegionSection
2. 如果当前基址没有创建过，会调用subpage_init来创建一个subpage_t结构
3. subpage_t结构为同一页的所有地址统一注册一个MemoryRegionSection，通过sub_section保存了这一页上所有地址在MemoryRegionSection数组中的索引

#### 虚拟机物理地址的设置

1. 遍历内存槽，查看要创建的slot是否与当前的内存条的slot有重合
2. 获取需要创建的页面个数，分配内存空间（这里存在检测：是否对齐，用户态设置是否允许大页）
3. 创建slot的内存槽，将其id号，虚拟机的物理内存地址，大小，对应用户态进程中分配的虚拟机地址等信息传入内存槽，并将该内存槽插入slots->memslots，并对齐按gfn从大到小排序

#### MMIO机制

1. QEMU申明一段内存作为MMIO内存，但这不会导致实际QEMU进程的内存分配
2. SeaBIOS会分配好所有设备MMIO对应的基址
3. 当Guest第一次访问MMIO的地址时，会发生EPT violation，产生VM Exit
4. KVM创建一个EPT页表，并设置页表项特殊标志
5. 虚拟机之后再访问对应的MMIO地址的时候就会产生EPT misconfig（因为上面异常处理时对页表项属性的设置是具有写和执行权限，却没有读权限，这是互相矛盾的，所以产生异常），从而产生VM Exit，退出到KVM，然后KVM负责将该事件分发到QEMU（分发是指将KVM_EXIT_MMIO信息里读的地址和长度都保存在了QEMU和KVM的共享内存空间vcpu->run->mmio中）
6. QEMU在得到这个退出信息后，根据AddressSpace结构体里面的AddressSpaceDispatch内的页表查找对应MemoryRegion，这样就找到读写该地址的回调函数